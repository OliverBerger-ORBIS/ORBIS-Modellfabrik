### DE

**Titel:** AI Lifecycle: Von Daten zu Modellen – und zurück in die Edge  
**One-liner:** AI wird industrietauglich, wenn Daten, Training, Deployment und Betrieb als Lifecycle gedacht sind.  
**Kundennutzen (3):**
*   Realtime-Entscheidungen dort, wo sie gebraucht werden (Edge)
    
*   Kontrollierter Modell-Rollout und Versionierung (Governance)
    
*   Kontinuierliche Verbesserung durch Feedback/Monitoring  
    **Pain Points (3):**
    
*   Daten sind nicht trainingsfähig (Qualität, Labeling, Kontext)
    
*   Modelle bleiben in PoCs stecken (kein Deployment-/Betriebsmodell)
    
*   Drift/Performance wird nicht überwacht  
    **Datenquellen:**
    
*   Business: Qualitätsanforderungen, Auftragskontext, Stammdaten
    
*   Shopfloor: Prozessdaten, Bilder/Signale, Qualitätsereignisse
    
*   Umwelt/Sensorik: optional zur Korrelation  
    **KPI/Outcome-Bezug:** FPY, Ausschuss, Nacharbeit, Reaktionszeit, Modellgüte/Drift-Indikatoren  
    **Orchestrierung / Systeminteraktion:**  
    Lifecycle: Sammeln/kontextualisieren → Training/Validierung (Cloud) → Deployment (Edge) → Monitoring/Feedback → Retraining. DSP unterstützt Orchestrierung und Provisioning der relevanten Daten/Modelle.  
    **Demonstrator vs produktive Lösung:** (Standard-Disclaimer DE)  
    **CTA:** AI Use-Case Discovery + Lifecycle Setup Workshop  
    **Caption:** AI Lifecycle verbindet Datenpipeline, Training, Deployment in die Edge und Monitoring zu einem kontrollierten Kreislauf.  
    **Alt-Text:** Diagramm, das die Schritte Daten → Training → Deployment → Monitoring → Feedback darstellt.
    

### EN

**Title:** AI Lifecycle: From Data to Models—Back to the Edge  
**One-liner:** Industrial AI requires a lifecycle: data, training, deployment, and operations.  
**Benefits:** real-time decisions at the edge, governed rollout/versioning, continuous improvement via feedback  
**Pain points:** data not ML-ready, no deployment/ops model, no drift monitoring  
**Data sources:** business context, shopfloor data/signals/images, optional environment  
**KPI/Outcome:** FPY/scrap, response time, model quality/drift indicators  
**Orchestration:** collect/contextualize → train/validate (cloud) → deploy (edge) → monitor/feedback → retrain  
**Disclaimer:** standard EN  
**CTA:** AI use-case discovery + lifecycle workshop  
**Caption:** The AI lifecycle links data pipelines, cloud training, edge deployment, and monitoring into a controlled loop.  
**Alt text:** Diagram showing data → training → deployment → monitoring → feedback.